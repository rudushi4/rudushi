# ğŸ¤– Rudushi - Automated AI Assistant via GitHub Actions

[![License](https://img.shields.io/badge/ğŸ“„-Apache%202.0-green)](LICENSE)
[![Model](https://img.shields.io/badge/ğŸ¤—-Hugging%20Face-orange)](https://huggingface.co/megharudushi/Rudushi)
[![Actions](https://img.shields.io/badge/âš™ï¸-GitHub%20Actions-blue)](./.github/workflows/)

**Rudushi** is a lightweight AI assistant that fine-tunes itself automatically using GitHub Actions! No GPU needed on your device - everything runs in the cloud! â˜ï¸âœ¨

---

## ğŸ¯ What is Rudushi?

Rudushi is a **1.1B parameter language model** (TinyLlama-based) that:
- âœ… **Fine-tunes itself** in the cloud using GitHub Actions
- âœ… **No GPU required** on your device
- âœ… **Runs on Android** (Termux optimized)
- âœ… **Optimized for coding** and agentic tasks
- âœ… **Deploys automatically** to Hugging Face

---

## ğŸš€ How It Works (Fully Automated!)

### 1ï¸âƒ£ **Trigger Fine-tuning**
Just click a button in GitHub Actions!

### 2ï¸âƒ£ **GitHub Actions Does The Rest**
- âœ… Downloads TinyLlama-1.1B
- âœ… Fine-tunes on Alpaca dataset (52K instructions)
- âœ… Uses LoRA (Rank 16) for efficiency
- âœ… Runs on **NVIDIA GPU** in the cloud
- âœ… Saves your custom model

### 3ï¸âƒ£ **Automatic Conversion & Upload**
- âœ… Converts model to GGUF format
- âœ… Uploads to Hugging Face Hub
- âœ… Creates beautiful model card
- âœ… Deploys to Hugging Face Spaces (web UI)

### 4ï¸âƒ£ **Download & Use**
- âœ… Download from Hugging Face
- âœ… Run in Termux on your Android device
- âœ… Chat with your custom Rudushi!

---

## ğŸ›ï¸ Automated Workflows

### Workflow 1: Fine-Tune Model
**File**: [.github/workflows/fine_tune.yml](./.github/workflows/fine_tune.yml)

**Triggers**: Manual dispatch

**What it does**:
- Runs on GPU runner (linux-cuda11.8-cudnn8-runtime)
- Installs Unsloth, PyTorch, Transformers
- Fine-tunes TinyLlama-1.1B on Alpaca
- Configurable steps (100/500/1000+)
- Saves model artifact
- Creates GitHub release

**Duration**: 30-90 minutes (depending on steps)

### Workflow 2: Convert & Upload
**File**: [.github/workflows/convert_and_upload.yml](./.github/workflows/convert_and_upload.yml)

**Triggers**: After fine-tuning completes

**What it does**:
- Downloads fine-tuned model
- Converts to GGUF using llama.cpp
- Quantizes to Q4_K_M (4-bit)
- Uploads to Hugging Face Hub
- Creates model card
- Tests the model

**Duration**: 10-15 minutes

### Workflow 3: Deploy Spaces
**File**: [.github/workflows/deploy_spaces.yml](./.github/workflows/deploy_spaces.yml)

**Triggers**: After upload completes

**What it does**:
- Creates Hugging Face Space
- Deploys Gradio web interface
- Connects to your model
- Makes it accessible via web browser

**Duration**: 2-5 minutes

---

## ğŸ”¥ Key Advantages

### Traditional Approach âŒ
- Need GPU on device
- Use Google Colab (time limits)
- Manual setup
- Manual upload
- Complex workflow

### **Our Approach** âœ…
- **GPU in the cloud** (GitHub Actions)
- **No time limits** (up to 6 hours)
- **Fully automated** (one click)
- **Automatic upload** to Hugging Face
- **Simple workflow** (just trigger!)

---

## ğŸ¯ Quick Start

### Step 1: Fork This Repository

```bash
# Fork on GitHub: https://github.com/rudushi4/rudushi/fork
```

### Step 2: Set GitHub Secrets

Go to `Settings â†’ Secrets and variables â†’ Actions`

Add these secrets:

| Secret Name | Value |
|-------------|-------|
| `HF_TOKEN` | Your Hugging Face token (write permission) |
| `HF_REPO` | `megharudushi/Rudushi` |

**Get HF Token**:
1. Go to: https://huggingface.co/settings/tokens
2. Click "New token"
3. Name: "Rudushi"
4. Role: **Write**
5. Copy token

### Step 3: Trigger Fine-tuning

1. Go to **Actions** tab
2. Select **"Fine-Tune Rudushi Model"**
3. Click **"Run workflow"**
4. Choose steps (100 for testing, 1000+ for production)
5. Click **"Run workflow"**

### Step 4: Wait & Relax! â˜•

GitHub Actions will:
- âœ… Fine-tune the model (30-90 min)
- âœ… Convert to GGUF (10 min)
- âœ… Upload to Hugging Face (5 min)
- âœ… Deploy to Spaces (5 min)

### Step 5: Use Your Rudushi!

**Download Model**: https://huggingface.co/megharudushi/Rudushi

**Web UI**: https://huggingface.co/spaces/YOUR_USERNAME/rudushi-spaces-rudushi

**Termux**: Transfer model and run:
```bash
./rudushi
# Select option 1: Chat with Rudushi
```

---

## ğŸ“Š Workflow Status

Check the status in the **Actions** tab:

| Status | Description |
|--------|-------------|
| ğŸŸ¢ Success | All workflows completed |
| ğŸ”´ Failed | Check logs for errors |
| ğŸŸ¡ In Progress | Currently running |

---

## ğŸ› ï¸ Manual Workflows

You can also run workflows manually:

### Fine-Tune Model
```bash
# Actions â†’ Fine-Tune Rudushi Model â†’ Run workflow
```

### Convert & Upload
```bash
# Actions â†’ Convert & Upload to Hugging Face â†’ Run workflow
```

### Deploy Spaces
```bash
# Actions â†’ Deploy to Hugging Face Spaces â†’ Run workflow
```

---

## ğŸ“ Repository Structure

```
rudushi/
â”œâ”€â”€ .github/workflows/          # GitHub Actions workflows
â”‚   â”œâ”€â”€ fine_tune.yml           # Auto fine-tuning
â”‚   â”œâ”€â”€ convert_and_upload.yml  # Auto conversion & upload
â”‚   â””â”€â”€ deploy_spaces.yml       # Auto Spaces deployment
â”‚
â”œâ”€â”€ app.py                      # Gradio web interface
â”œâ”€â”€ rudushi_chat.py             # Termux chat interface
â”œâ”€â”€ requirements.txt            # Python dependencies
â”‚
â””â”€â”€ README.md                   # This file
```

---

## ğŸ“ Customization

### Change Training Steps

Edit `.github/workflows/fine_tune.yml`:

```yaml
inputs:
  steps:
    description: 'Number of training steps'
    required: true
    default: '1000'  # â† Change here
```

### Different Dataset

Edit `fine_tune.yml`, replace dataset:

```python
dataset = load_dataset("your/dataset", split="train")
```

### Custom Model Size

Currently supports:
- TinyLlama-1.1B âœ…
- Add your own in `fine_tune.yml`

---

## ğŸ“ˆ Expected Results

### Model Quality vs Steps

| Steps | Time | Quality | Use Case |
|-------|------|---------|----------|
| 100 | 30 min | Basic | Testing |
| 500 | 90 min | Good | Personal use |
| 1000 | 3+ hours | Excellent | Production |
| 2000 | 6+ hours | SOTA | Research |

### Performance on Mobile

| Model Size | RAM | Speed | Quality |
|------------|-----|-------|---------|
| 1.1B | 500MB | 5-10 tok/s | â­â­â­ |
| 3B | 1.2GB | 2-5 tok/s | â­â­â­â­ |
| 7B | 3GB | 1-2 tok/s | â­â­â­â­â­ |

---

## ğŸ› Troubleshooting

### Workflow Failed

**Check logs**:
1. Actions tab â†’ Failed workflow
2. Click on job
3. Click on failing step
4. Read error message

**Common issues**:
- `HF_TOKEN` missing or invalid
- Repository permissions
- Out of memory (reduce batch size)

### Upload Failed

**Solutions**:
- Ensure `HF_TOKEN` has **Write** permission
- Check `HF_REPO` secret is correct
- Repository must exist (will be created)

### Model Quality Poor

**Solutions**:
- Increase training steps
- Use better dataset
- Adjust learning rate

---

## ğŸ¯ Use Cases

### 1. Personal AI Assistant
Fine-tune on your conversations and use daily

### 2. Coding Assistant
Optimize for programming tasks

### 3. Chatbot
Deploy in Spaces for public access

### 4. Mobile AI
Run offline on Android with Termux

---

## ğŸ“š Documentation

- **Full Guide**: [README.md](./README.md)
- **Fine-tuning**: [FINETUNE_GUIDE.md](./FINETUNE_GUIDE.md)
- **Rudushi Chat**: [RUDUSHI_README.md](./RUDUSHI_README.md)
- **Technical**: [PROJECT_SUMMARY.md](./PROJECT_SUMMARY.md)

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch
3. Commit changes
4. Push to branch
5. Create Pull Request

---

## ğŸ“„ License

**Apache 2.0** - See [LICENSE](LICENSE)

---

## ğŸ‰ Try It Now!

1. **Fork**: https://github.com/rudushi4/rudushi/fork
2. **Set Secrets**: Add `HF_TOKEN` and `HF_REPO`
3. **Run Workflow**: Actions â†’ Fine-Tune Rudushi â†’ Run
4. **Wait**: ~50 minutes total
5. **Use**: Chat with your custom Rudushi!

---

**No GPU? No problem! GitHub Actions has you covered! â˜ï¸âœ¨**

## â­ Star This Repo

If you found this useful, â­ star the repository!

---

**Made with â¤ï¸ using GitHub Actions & Hugging Face**
