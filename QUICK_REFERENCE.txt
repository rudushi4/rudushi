â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                  ğŸ¯ RUDUSHI QUICK REFERENCE                            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“± YOUR DEVICE: Android 13, 7.5GB RAM, ARM64

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸš€ FASTEST WAY TO START (3 commands):

  1. Download model:
     ./05_download_model.sh

  2. Test it:
     /data/data/com.termux/files/home/llama.cpp/build/bin/llama-cli \
       -m /data/data/com.termux/files/home/rudushi_model/TinyLlama-1.1B-Chat-v1.0.Q4_K_M.gguf \
       -p "Hello" -n 50

  3. Chat:
     /data/data/com.termux/files/home/llama.cpp/build/bin/llama-cli \
       -m /data/data/com.termux/files/home/rudushi_model/TinyLlama-1.1B-Chat-v1.0.Q4_K_M.gguf \
       --interactive --mlock

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“‚ KEY LOCATIONS:

  Scripts:      /data/data/com.termux/files/home/rudushi/*.py /data/data/com.termux/files/home/rudushi/*.sh
  Models:       /data/data/com.termux/files/home/rudushi_model/
  llama.cpp:    /data/data/com.termux/files/home/llama.cpp/
  Binary:       /data/data/com.termux/files/home/llama.cpp/build/bin/llama-cli

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ’¾ DOWNLOAD MODELS:

  TinyLlama-1.1B (550MB):
    https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF

  Qwen2-1.5B (940MB):
    https://huggingface.co/Qwen/Qwen2-1.5B-Instruct-GGUF

  Phi-3-Mini-4K (2.3GB):
    https://huggingface.co/mradermacher/Phi-3-mini-4k-instruct-gguf

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âš™ï¸ COMMON COMMANDS:

  Quick test:
  ./llama-cli -m MODEL.gguf -p "Question?" -n 100

  Interactive chat:
  ./llama-cli -m MODEL.gguf --interactive --mlock

  Better quality:
  ./llama-cli -m MODEL.gguf -p "Prompt" -n 512 --temp 0.5

  Performance mode:
  ./llama-cli -m MODEL.gguf -p "Prompt" -t 4 -b 512 --mlock

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“– DOCUMENTATION:

  SETUP_STATUS.md      â†’ Setup guide for YOUR device
  README.md            â†’ Full project documentation
  PROJECT_SUMMARY.md   â†’ Technical details

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âš¡ YOUR DEVICE CAN RUN:

  âœ… TinyLlama-1.1B (550MB) - Multiple copies!
  âœ… Qwen2-1.5B (940MB) - Excellent quality
  âœ… Phi-3-Mini-4K (2.3GB) - Best capability

  With 7.5GB RAM, you have room to spare! ğŸ‰

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ› TROUBLESHOOTING:

  Out of memory?
    â†’ Close other apps, use -c 1024

  Slow performance?
    â†’ Use --mlock, -t 4, -b 512

  Can't download model?
    â†’ Get HF token: https://huggingface.co/settings/tokens
    â†’ Or download via browser and transfer

  Need help?
    â†’ All scripts have --help option
    â†’ Read documentation files

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ’¡ PRO TIP:

  Start with TinyLlama-1.1B (fastest), then try larger models
  as you get comfortable!

